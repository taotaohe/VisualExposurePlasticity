{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, warnings, time, datetime\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import scipy, mne, random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io, stats, interpolate\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 'D:/Dropbox/Projects/featureReplay/'    \n",
    "SUBJECTS = ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10',\n",
    "            'S11','S12','S13','S14','S15','S16','S17','S18','S19','S20',\n",
    "            'S21','S22','S23','S24','S25','S26','S27','S28','S29','S30',\n",
    "            'S31','S32','S33','S34','S35']\n",
    "\n",
    "# !! Important: if you only select one subject, you must still write as [n-1:n]\n",
    "selected_subj = SUBJECTS[:18]\n",
    "n_subjects    = len(selected_subj)\n",
    "print(['Running Subjects:'] + selected_subj)\n",
    "\n",
    "# Get selected channel index (occipital)\n",
    "chans_all       = np.loadtxt(project_path + 'data_v5/misc_data/channels_all.txt', dtype='str')\n",
    "chans_occipital = np.loadtxt(project_path + 'data_v5/misc_data/occipital_channels.txt', dtype='str')\n",
    "chans_idx       = np.where(np.in1d(chans_all, chans_occipital) == True)[0]\n",
    "\n",
    "# params for decoding\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(C=0.5, penalty='l2', max_iter=10000, class_weight='balanced', \n",
    "                                                         multi_class='ovr', solver='liblinear'))\n",
    "proba = np.zeros((n_subjects, 3, 775, 96, 4)) # n_subj, n_conditions, n_times, n_maxTrials(96), n_orientations\n",
    "proba[:] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average trials before training and test\n",
    "for s in range(n_subjects):\n",
    "    start = time.time()\n",
    "    subj_id = selected_subj[s]\n",
    "    print('>>> loading data for subject:', subj_id)\n",
    "    \n",
    "    ## ================ load train data (modelTrain) =============== ##\n",
    "    ## load epochs data of orientation period\n",
    "    cond_data = project_path + 'data_v5/%s/%s_modelTrain_epochs_all_resample250_ica-epo.fif' %(subj_id, subj_id)\n",
    "    epochs_all = mne.read_epochs(cond_data, preload=True)\n",
    "    X_ori = epochs_all.get_data() # n_trials * n_channels * n_times\n",
    "    y_ori = epochs_all.events[:,2]\n",
    "  \n",
    "    ## load epochs data of ITI period\n",
    "    iti_data = project_path + 'data_v5/%s/%s_modelTrain_epochs_all_resample250_ica_ITI-epo.fif' %(subj_id, subj_id)\n",
    "    epochs_iti = mne.read_epochs(iti_data, preload=True)\n",
    "    X_iti = epochs_iti.get_data() # n_trials * n_channels * n_times\n",
    "    y_iti = np.zeros(X_iti.shape[0]) # all iti period labels are 0\n",
    "\n",
    "    ## concatenate orientation data and iti data\n",
    "    X_train = np.vstack((X_ori, X_iti))\n",
    "    y_train = np.hstack((y_ori, y_iti)) \n",
    "\n",
    "    ## select relevant channels (occipital cortex)\n",
    "    X_train = np.mean(X_train[:,chans_idx,100:200],axis=2)\n",
    "\n",
    "    repeat_num = 10\n",
    "    X_train_perm = np.zeros(repeat_num, dtype=object)\n",
    "    y_train_perm = np.zeros(repeat_num, dtype=object)\n",
    "    for it in range(repeat_num): # \n",
    "        shuffle_order = np.arange(len(y_train))\n",
    "        np.random.shuffle(shuffle_order) # shuffle the row of the array\n",
    "        y_train_shuffle = y_train[shuffle_order]\n",
    "        X_train_shuffle = X_train[shuffle_order,:]\n",
    "\n",
    "        ## average relevant trials before decoding\n",
    "        n_classes = 5\n",
    "        X_per_class = np.zeros(n_classes, dtype=object)\n",
    "        t_num_per_class = np.zeros(n_classes)\n",
    "        for ic in range(n_classes): # 5 classes, including iti period (0)\n",
    "            class_idx = np.where(y_train_shuffle == ic)[0]\n",
    "            X_this_class = X_train_shuffle[class_idx] # n_trials x n_features\n",
    "            everyNrows = 2 # average every N trials 5   \n",
    "            \n",
    "            if len(class_idx)%everyNrows > 0:\n",
    "                rows = len(class_idx)//everyNrows\n",
    "                reminder = len(class_idx)%everyNrows\n",
    "                X_tmp = X_this_class[:(len(class_idx)-reminder)]\n",
    "                X_tmp2 = X_tmp.transpose().reshape(-1,everyNrows).mean(1).reshape(X_tmp.shape[1],-1).transpose()\n",
    "                X_tmp3 = np.concatenate((X_tmp2, X_this_class[-reminder:]))            \n",
    "            else:\n",
    "                X_tmp3 = X_this_class.transpose().reshape(-1,everyNrows).mean(1).reshape(X_this_class.shape[1],-1).transpose()\n",
    "            \n",
    "            X_per_class[ic] = X_tmp3\n",
    "            t_num_per_class[ic] = X_tmp3.shape[0]\n",
    "    \n",
    "        X_train_perm[it] = np.concatenate(X_per_class)\n",
    "        y_train_perm[it] = np.arange(n_classes).repeat(t_num_per_class.astype(int))\n",
    "\n",
    "    X_train_aver = np.mean(X_train_perm)\n",
    "    y_train_aver = y_train_perm[0]\n",
    "\n",
    "    ## ================ load test data (mainPost) =============== ##\n",
    "    cond_data = project_path + 'data_v5/%s/%s_mainPost_epochs_all_resample250_ica-epo.fif' %(subj_id, subj_id)\n",
    "    epochs_all = mne.read_epochs(cond_data, preload=True)\n",
    "    X_test_all = epochs_all.get_data() # n_trials * n_channels * n_times\n",
    "    y_test_all = epochs_all.events[:,2]\n",
    "\n",
    "    ## select relevant channels\n",
    "    X_test_all = X_test_all[:,chans_idx,:] # select occipital cortex\n",
    "\n",
    "    # find the true orientation order for the current subject    \n",
    "    f_mat = scipy.io.loadmat(project_path + 'data_v5/behavioral_data/%s/MainTask/params_PostTest_%s_R01.mat' %(subj_id, subj_id))\n",
    "    test_dir = f_mat['p']['Orient'][0,0].ravel()\n",
    "    test_dir_idx = (test_dir+90)/90 # orientation order, e.g., 1 2 3 4\n",
    "    \n",
    "    # select relevant trials for each condition\n",
    "    selection = np.zeros(len(y_test_all))\n",
    "    selection[y_test_all == test_dir_idx[0]] += 1       # full sequence condition\n",
    "    selection[y_test_all == (test_dir_idx[0]+10)] += 2  # Start condition\n",
    "    selection[y_test_all == (test_dir_idx[3]+10)] += 3  # End condition\n",
    "    \n",
    "    ## ================ do classification from here ================ ##       \n",
    "    clf.fit(X_train_aver, y_train_aver) \n",
    "    \n",
    "    ## apply trained model to each condition and each timepoint\n",
    "    for t in range(X_test_all.shape[-1]): # the last dimension is times\n",
    "        X_test_this_time = X_test_all[:,:,t]\n",
    "\n",
    "        for ic in range(3): # 3 conditions              \n",
    "            idx = np.where(selection == (ic+1))[0]\n",
    "            X_test_cond = X_test_this_time[idx,:]\n",
    "\n",
    "            repeat_num = 30\n",
    "            X_test_cond_aver = np.zeros(repeat_num, dtype=object)\n",
    "            for ita in range(repeat_num):\n",
    "                np.random.shuffle(X_test_cond)\n",
    "                ## average relevant trials before decoding\n",
    "                everyNrows = 5 # average every N trials\n",
    "                trialNum = X_test_cond.shape[0]\n",
    "                if trialNum%everyNrows > 0:\n",
    "                    rows = trialNum//everyNrows\n",
    "                    reminder = trialNum%everyNrows\n",
    "                    X_tmp = X_test_cond[:(trialNum-reminder)]\n",
    "                    X_tmp2 = X_tmp.transpose().reshape(-1,everyNrows).mean(1).reshape(X_tmp.shape[1],-1).transpose()\n",
    "                    X_test_cond_aver[ita] = np.concatenate((X_tmp2, np.mean(X_test_cond[-reminder:])))            \n",
    "                else:\n",
    "                    X_test_cond_aver[ita] = X_test_cond.transpose().reshape(-1,everyNrows).mean(1).reshape(X_test_cond.shape[1],-1).transpose()\n",
    "\n",
    "            X_test_cond_shuff = np.mean(X_test_cond_aver)  \n",
    "            # predict main post data\n",
    "            y_pred = clf.predict_proba(X_test_cond_shuff) \n",
    "            \n",
    "            # store probabilities for each trial\n",
    "            proba[s,ic,t,:len(y_pred),:] = y_pred[:,1:][:,test_dir_idx.astype(int)-1]\n",
    "            \n",
    "    # # check spent duration\n",
    "    # print(subj_id, \" took \", str(datetime.timedelta(seconds=time.time()-start)))\n",
    "\n",
    "## save data\n",
    "data_path = project_path + 'data_v5/saved_source_data/'\n",
    "if not os.path.exists(data_path): os.makedirs(data_path)\n",
    "np.save(data_path+'probability_mainPost_occipital_double_mean', proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocolor plot\n",
    "data_path = project_path + 'data_v5/saved_source_data/'\n",
    "proba = np.load(data_path + 'probability_mainPost_occipital_double_mean.npy', allow_pickle=True)\n",
    "proba_mean = np.nanmean(proba, axis=(0,3)) # n_conds, n_times, n_classes\n",
    "\n",
    "# start plotting here\n",
    "conditions = ['Full sequence', 'Start only', 'End only']\n",
    "fig, axs = plt.subplots(nrows=1,ncols=3,sharex=True,sharey=True,figsize=(18, 5))\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "\n",
    "for icond in range(3):\n",
    "    ax = axs[icond] \n",
    "\n",
    "    y_filtered = savgol_filter(proba_mean[icond], window_length=51, polyorder=1, axis=0)\n",
    "\n",
    "    im = ax.pcolor(y_filtered)\n",
    "    ax.set_xlabel('Orientation', fontsize=14)\n",
    "    ax.set_ylabel('Time (s)', fontsize=14)\n",
    "    ax.set_xticks(np.arange(4)+.5)\n",
    "    ax.set_xticklabels(np.arange(4)+1)\n",
    "    ax.set_yticks([0, 75, 200, 325, 450, 575, 700])\n",
    "    ax.set_yticklabels([-0.3, 0, 0.5, 1, 1.5, 2, 2.5])\n",
    "    ax.set_title('%s' %(conditions[icond]), fontsize=16)\n",
    "    ax.tick_params(axis = 'both', which = 'major', direction='in', top=False, right=False, labelsize = 14)\n",
    "    ax.invert_yaxis()\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.ax.get_yaxis().labelpad = 13\n",
    "    cbar.ax.set_ylabel('Decoding probability', rotation=90, fontsize=16)\n",
    "    \n",
    "## save figures\n",
    "save_figure = False\n",
    "if save_figure:\n",
    "    fig_path = project_path + '/data_v5/saved_figures/mainPost_proba_rs250_ica_occipital/'\n",
    "    if not os.path.exists(fig_path): os.makedirs(fig_path);\n",
    "    fig.savefig(fig_path+\"mainPost_probability_meanOverTrials_pcolor.pdf\", bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw data curve\n",
    "data_path = project_path + 'data_v5/saved_source_data/'\n",
    "proba = np.load(data_path + 'probability_mainPost_occipital_double_mean.npy', allow_pickle=True)\n",
    "proba_mean = np.nanmean(proba, axis=(0,3)) # n_conds, n_times, n_classes\n",
    "\n",
    "# start plotting here\n",
    "conditions = ['Full sequence', 'Start-only', 'End-only']\n",
    "fig, axs = plt.subplots(nrows=1,ncols=3,sharex=False,sharey=False,figsize=(18, 5))\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "\n",
    "for i in range(3): \n",
    "    ax = axs[i]\n",
    "\n",
    "    for j in range(4): # predicted label probability\n",
    "        y_filtered = proba_mean[i,:,j]\n",
    "\n",
    "        if i == 0: # plot legend in fig.1 only\n",
    "            ax.plot(y_filtered, lw=1.5, label='%s$^{\\circ}$' %(j*90))\n",
    "            ax.legend(loc=1,fontsize=14,frameon=False)\n",
    "        else:\n",
    "            ax.plot(y_filtered, lw=1.5)\n",
    "    \n",
    "    # plot highlight area\n",
    "    for low, high in zip([75, 250, 425, 600], [175, 350, 525, 700]):\n",
    "        ax.axvspan(low, high, facecolor='gray', alpha=.2)\n",
    "    # set parameters for figures\n",
    "    ax.set_title(conditions[i], fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax.set_ylabel('Decoding probability (%)', fontsize=12)\n",
    "    ax.set_xticks((75, 175, 250, 350, 425, 525, 600, 700))\n",
    "    ax.set_xticklabels((0,.4, .7,1.1, 1.4,1.8, 2.1,2.5))\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(axis='both', which='both', direction='out', labelsize = 12)\n",
    "\n",
    "## save figures\n",
    "save_figure = False\n",
    "if save_figure:\n",
    "    fig_path = project_path + '/data_v5/saved_figures/mainPost_proba_rs250_ica_occipital/'\n",
    "    if not os.path.exists(fig_path): os.makedirs(fig_path);\n",
    "    fig.savefig(fig_path+\"mainPost_probability_meanOverTrials_curve_raw.pdf\", bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth the curve for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(775)\n",
    "data_path = project_path + 'data_v5/saved_source_data/'\n",
    "proba = np.load(data_path + 'probability_mainPost_occipital_double_mean.npy', allow_pickle=True)\n",
    "proba_mean = np.nanmean(proba, axis=(0,3)) # n_conds, n_times, n_classes\n",
    "proba_sem = stats.sem(np.nanmean(proba, axis=3), axis=0) # n_conds, n_times, n_classes\n",
    "\n",
    "# start plotting here\n",
    "conditions = ['Full sequence', 'Start-only', 'End-only']\n",
    "fig, axs = plt.subplots(nrows=1,ncols=3,sharex=False,sharey=False,figsize=(18, 5))\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "\n",
    "for i in range(3): \n",
    "    ax = axs[i]\n",
    "    \n",
    "    for j in range(4): # predicted label probability\n",
    "        y_filtered = savgol_filter(proba_mean[i,:,j], window_length=51, polyorder=1, mode='interp')\n",
    "\n",
    "        if i == 2: # plot legend in fig.1 only\n",
    "            ax.plot(y_filtered, lw=2, label='%s$^{\\circ}$' %(j*90))\n",
    "            ax.legend(loc=1,fontsize=12,frameon=False)\n",
    "        else:\n",
    "            ax.plot(y_filtered, lw=2)\n",
    "        ax.fill_between(times, y_filtered-proba_sem[i,:,j], y_filtered+proba_sem[i,:,j], edgecolor='none',alpha=.3)\n",
    "\n",
    "    # plot highlight area\n",
    "    for low, high in zip([75, 250, 425, 600], [175, 350, 525, 700]):\n",
    "        ax.axvspan(low, high, facecolor='gray', alpha=.2)\n",
    "    # set parameters for figures\n",
    "    ax.set_title(conditions[i], fontsize=12)\n",
    "    ax.set_xlabel('Time relative to trial onset (s)', fontsize=12)\n",
    "    ax.set_ylabel('Decoding probability (%)', fontsize=12)\n",
    "    ax.set_xticks((75, 175, 250, 350, 425, 525, 600, 700))\n",
    "    ax.set_xticklabels((0,.4, .7,1.1, 1.4,1.8, 2.1,2.5))\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(axis='both', which='both', direction='out', labelsize = 12)\n",
    "    ax.set_ylim(0,0.37)\n",
    "\n",
    "## save figures\n",
    "save_figure = False\n",
    "if save_figure:\n",
    "    fig_path = project_path + '/data_v5/saved_figures/mainPost_proba_rs250_ica_occipital/'\n",
    "    if not os.path.exists(fig_path): os.makedirs(fig_path);\n",
    "    fig.savefig(fig_path+\"mainPost_probability_meanOverTrials_curve_smooth.pdf\", bbox_inches='tight',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
