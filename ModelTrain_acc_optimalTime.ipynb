{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,glob,warnings, heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mne, scipy.io\n",
    "from scipy import io, stats, interpolate\n",
    "sys.path.append(\"D:/Dropbox/Projects/featureReplay/misc/\")\n",
    "import draw_sig_contour as dsc\n",
    "\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, KFold\n",
    "warnings.filterwarnings('ignore')\n",
    "# make plot interactive\n",
    "%matplotlib qt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 'D:/Dropbox/Projects/featureReplay/'\n",
    "SUBJECTS = ['S01','S02','S03','S04','S05','S06','S07','S08','S09','S10',\n",
    "            'S11','S12','S13','S14','S15','S16','S17','S18','S19','S20',\n",
    "            'S21','S22','S23','S24','S25','S26','S27','S28','S29','S30',\n",
    "            'S31','S32','S33','S34','S35']\n",
    "\n",
    "# !! Important: if you only select one subject, you must still write as [n-1:n]\n",
    "selected_subj = SUBJECTS[:18]\n",
    "print(['Running Subjects:'] + selected_subj)\n",
    "\n",
    "# Get selected channel index (occipital)\n",
    "chans_all       = np.loadtxt(project_path + 'data_v5/misc_data/channels_all.txt', dtype='str')\n",
    "chans_occipital = np.loadtxt(project_path + 'data_v5/misc_data/occipital_channels.txt', dtype='str')\n",
    "chans_idx       = np.where(np.in1d(chans_all, chans_occipital) == True)\n",
    "\n",
    "# params for decoding\n",
    "cv = LeaveOneOut() #5\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(C=1, penalty='l1', multi_class='ovr', solver='liblinear')) \n",
    "time = GeneralizingEstimator(clf, n_jobs=20, scoring='accuracy') # define temporal generalization decoding\n",
    "time_decod = SlidingEstimator(clf, n_jobs=20, scoring='accuracy') # use in permutation, faster\n",
    "accuracies = np.zeros((n_subjects, 4, 325, 325)) # true_labels, times, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run decoding over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(n_subjects):\n",
    "    subj_id = selected_subj[s]\n",
    "    print('>>> loading data for subject:', subj_id)\n",
    "    \n",
    "    ## load data\n",
    "    cond_data = project_path + 'data_v5/%s/%s_modelTrain_epochs_all_resample250_ica-epo.fif' %(subj_id, subj_id)\n",
    "    epochs_all = mne.read_epochs(cond_data, preload=True)\n",
    "    X = epochs_all.get_data() # n_trials * n_channels * n_times\n",
    "    y = epochs_all.events[:,2]\n",
    "    \n",
    "    ## select relevant channels\n",
    "    XX = np.squeeze(X[:,chans_idx,:]) # select occipital cortex\n",
    "\n",
    "    ## classification\n",
    "    pred = cross_val_multiscore(time, XX, y, cv=cv, n_jobs=20)\n",
    "    \n",
    "    ## store accuracies for each true label\n",
    "    for ilabel in range(4): # true label\n",
    "        accuracies[s,ilabel,:,:] = np.mean(pred[y==(ilabel+1),:,:], axis=0) # average across all trials per label\n",
    "    \n",
    "# save data\n",
    "data_path = project_path + 'data_v5/saved_source_data/'  \n",
    "if not os.path.exists(data_path): os.makedirs(data_path)\n",
    "np.save(data_path+'acc_rs250_ica_occipital_find_multiOptimalTime', accuracies)\n",
    "np.save(data_path+'time_points_rs250', epochs_all.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = project_path + 'data_v5/saved_source_data/'\n",
    "acc = np.load(data_path + 'acc_rs250_ica_occipital_find_multiOptimalTime.npy') # n_subjects*n_times*n_times\n",
    "\n",
    "acc = acc * 100 \n",
    "times = np.load(data_path + 'time_points_rs250.npy') \n",
    "\n",
    "# calculate diagonal mean, SEM\n",
    "acc_diag = np.zeros((n_subjects, 4, acc.shape[-1]))\n",
    "for isubj in range(n_subjects):\n",
    "    for ilabel in range(4):\n",
    "        acc_diag[isubj,ilabel,:] = np.diag(acc[isubj,ilabel])\n",
    "\n",
    "acc_mean = np.mean(acc_diag, axis=0)\n",
    "acc_sem = stats.sem(acc_diag, axis=0)\n",
    "\n",
    "# calculate optimal time for each subject\n",
    "optimal_time_idx = np.zeros((n_subjects,4))\n",
    "optimal_times = np.zeros((n_subjects,4))\n",
    "acc_per_subj = np.zeros((n_subjects,4))\n",
    "for isubj in range(n_subjects):\n",
    "    for ilabel in range(4):\n",
    "            \n",
    "        optimal_time_idx[isubj,ilabel] = np.argmax(np.diag(acc[isubj,ilabel])[floor_thr:ceil_thr]) + floor_thr\n",
    "        optimal_times[isubj,ilabel] = times[int(optimal_time_idx[isubj,ilabel])]\n",
    "        acc_per_subj[isubj,ilabel] = acc_diag[isubj,ilabel,int(optimal_time_idx[isubj,ilabel])]\n",
    "        print('%s label:%s optimal time: %s ms, index %s' %(selected_subj[isubj], ilabel, optimal_times[isubj,ilabel]*1000, int(optimal_time_idx[isubj,ilabel])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot mean decoding accuracies across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "color1 = 'darkorange'\n",
    "color2 = 'limegreen'\n",
    "\n",
    "# start plotting here\n",
    "fig, axs = plt.subplots(nrows=2,ncols=4,sharex=False,sharey=False,figsize=(26, 2*6))\n",
    "\n",
    "for ilabel in range(4):\n",
    "    \n",
    "    ################# Plot the full matrix #################      \n",
    "    # Calculate statistical thresholds\n",
    "    t_obs, clusters, cluster_pv, h0 = mne.stats.spatio_temporal_cluster_1samp_test((acc[:,ilabel,:,:]-1/4.*100), n_permutations=1024, out_type='mask', n_jobs=20)  \n",
    "    # format p_values to get same dimensionality as X\n",
    "    p_values = np.ones_like(acc[0,ilabel,:,:])\n",
    "    for clu, pval in zip(clusters, cluster_pv):\n",
    "        p_values[clu] = pval\n",
    "    mask = p_values < 0.05\n",
    "    \n",
    "    ax = axs[0, ilabel]\n",
    "    im = dsc.plot_contour_image(acc[:,ilabel,:,:].mean(0), times, ax=ax, mask=mask, vmin=25, vmax=35,\n",
    "                                draw_mask=False, draw_contour=True, colorbar=True,\n",
    "                                draw_diag=True, draw_zerolines=True,\n",
    "                                mask_alpha=.5);    \n",
    "    ax.set_xlabel('Testing Time (s)', fontsize=14)\n",
    "    ax.set_ylabel('Training Time (s)', fontsize=14)\n",
    "    ax.set_title('Mean Temporal Generalization Ori%s' %(ilabel*90), fontsize=14)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.tick_params(axis = 'both', which = 'major', direction='in', top=False, right=False, labelsize = 12)\n",
    "#     plt.colorbar(im, ax=ax)\n",
    "\n",
    "    ################# plot the diagonal line #################\n",
    "    ## plot statistical lines\n",
    "    t_obs_diag, cluster_diag, cluster_pv_diag, H0_diag = mne.stats.permutation_cluster_1samp_test((acc_diag[:,ilabel,:]-1/4.*100), n_permutations=1024, n_jobs=20)\n",
    "    sig_idx_diag = np.array(np.where(cluster_pv_diag < 0.05)).ravel()\n",
    "                \n",
    "    ax = axs[1, ilabel]\n",
    "    ax.axhline(100/4., color='k', linestyle='--', alpha=0.8, lw=1.5)\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha=0.8, lw=1.5) \n",
    "    \n",
    "    if ilabel == 0:\n",
    "        idx2 = heapq.nlargest(5, range(len(acc_mean[0])), key=acc_mean[0].__getitem__)[1] # get the index of second largest number\n",
    "        ax.axvline(times[idx2], color='k', linestyle='-', alpha=0.8, lw=1.5) \n",
    "    else:\n",
    "        ax.axvline(times[np.argmax(acc_mean[ilabel])], color='k', linestyle='-', alpha=0.8, lw=1.5) \n",
    "\n",
    "    ax.plot(times, acc_mean[ilabel], color=color1, lw=2)\n",
    "    ax.fill_between(times, acc_mean[ilabel]-acc_sem[ilabel], acc_mean[ilabel]+acc_sem[ilabel], color=color1,edgecolor='none',alpha=.35)\n",
    "    # plot statistical line\n",
    "    for i in range(len(sig_idx_diag)):\n",
    "        if len(times[cluster_diag[sig_idx_diag[i]]]) >= 10: # plot at least 10 continous sig. time points\n",
    "            ax.plot(times[cluster_diag[sig_idx_diag[i]]], np.repeat(20,len(times[cluster_diag[sig_idx_diag[i]]])),'k-', lw=3.5)\n",
    "            \n",
    "    ax.set_title('Mean decoding performance Ori%s' %(ilabel*90), fontsize=14)\n",
    "    ax.set_ylim([18, 42])\n",
    "    ax.set_xlabel('Time relative to stimulus onset (s)', fontsize=14);\n",
    "    ax.set_ylabel('Accuracies (%)', fontsize=14);\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(axis = 'both', which = 'major', direction='in', top=False, right=False, labelsize = 14)\n",
    "\n",
    "## save figures\n",
    "save_figure = False\n",
    "if save_figure:\n",
    "    fig_path = project_path + '/data_v5/saved_figures/modelTrain_rs250_ica_occipital/'\n",
    "    if not os.path.exists(fig_path): os.makedirs(fig_path);\n",
    "    fig.savefig(fig_path+\"modelTrain_acc_mean_find_multiOptimalTime_raw.pdf\", bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot smoothed data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_smooth = np.zeros(4,dtype=object)\n",
    "acc_sem_smooth  = np.zeros(4,dtype=object)\n",
    "for i in range(4):\n",
    "    acc_mean_smooth[i] = interpolate.interp1d(times, acc_mean[i,:], kind='linear')\n",
    "    acc_sem_smooth[i]  = interpolate.interp1d(times, acc_sem[i,:], kind='linear')\n",
    "    \n",
    "times_smooth = np.linspace(min(times),max(times),100) # how many time points do you want now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "color1 = 'darkorange'\n",
    "color2 = 'limegreen'\n",
    "\n",
    "# start plotting here\n",
    "fig, axs = plt.subplots(nrows=2,ncols=4,sharex=False,sharey=False,figsize=(26, 2*6))\n",
    "\n",
    "for ilabel in range(4):\n",
    "    ################# Plot the full matrix #################      \n",
    "    # Calculate statistical thresholds\n",
    "    t_obs, clusters, cluster_pv, h0 = mne.stats.spatio_temporal_cluster_1samp_test((acc[:,ilabel,:,:]-1/4.*100), n_permutations=1024, out_type='mask', n_jobs=20)  \n",
    "    # format p_values to get same dimensionality as X\n",
    "    p_values = np.ones_like(acc[0,ilabel,:,:])\n",
    "    for clu, pval in zip(clusters, cluster_pv):\n",
    "        p_values[clu] = pval\n",
    "    mask = p_values < 0.05\n",
    "    \n",
    "    ax = axs[0, ilabel]\n",
    "    im = dsc.plot_contour_image(acc[:,ilabel,:,:].mean(0), times, ax=ax, mask=mask, vmin=25, vmax=35,\n",
    "                                draw_mask=False, draw_contour=True, colorbar=True,\n",
    "                                draw_diag=True, draw_zerolines=True,\n",
    "                                mask_alpha=.5);    \n",
    "    ax.set_xlabel('Testing Time (s)', fontsize=14)\n",
    "    ax.set_ylabel('Training Time (s)', fontsize=14)\n",
    "    ax.set_title('Mean Temporal Generalization Ori%s' %(ilabel*90), fontsize=14)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.tick_params(axis = 'both', which = 'major', direction='in', top=False, right=False, labelsize = 12)\n",
    "#     plt.colorbar(im, ax=ax)\n",
    "\n",
    "    ################# plot the diagonal line #################\n",
    "    ## plot statistical lines\n",
    "    t_obs_diag, cluster_diag, cluster_pv_diag, H0_diag = mne.stats.permutation_cluster_1samp_test((acc_diag[:,ilabel,:]-1/4.*100), n_permutations=1024, n_jobs=20)\n",
    "    sig_idx_diag = np.array(np.where(cluster_pv_diag < 0.05)).ravel()\n",
    "                \n",
    "    ax = axs[1, ilabel]\n",
    "    ax.axhline(100/4., color='k', linestyle='--', alpha=0.8, lw=1.5)\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha=0.8, lw=1.5) \n",
    "    \n",
    "    if ilabel == 0: # because the first peak was not sig. in 0 deg\n",
    "        idx2 = heapq.nlargest(5, range(len(acc_mean[0])), key=acc_mean[0].__getitem__)[1] # get the index of second largest number\n",
    "        ax.axvline(times[idx2], color='k', linestyle='-', alpha=0.8, lw=1.5) \n",
    "    else:\n",
    "        ax.axvline(times[np.argmax(acc_mean[ilabel])], color='k', linestyle='-', alpha=0.8, lw=1.5) \n",
    "\n",
    "    ax.plot(times_smooth, acc_mean_smooth[ilabel](times_smooth), color=color1, lw=2)\n",
    "    ax.fill_between(times_smooth, acc_mean_smooth[ilabel](times_smooth)-acc_sem_smooth[ilabel](times_smooth),\n",
    "                    acc_mean_smooth[ilabel](times_smooth)+acc_sem_smooth[ilabel](times_smooth), color=color1,edgecolor='none',alpha=.35)\n",
    "    # plot statistical line\n",
    "    for i in range(len(sig_idx_diag)):\n",
    "        if len(times[cluster_diag[sig_idx_diag[i]]]) >= 10: # plot at least 10 continous sig. time points\n",
    "            ax.plot(times[cluster_diag[sig_idx_diag[i]]], np.repeat(20,len(times[cluster_diag[sig_idx_diag[i]]])),'k-', lw=3.5)\n",
    "            \n",
    "    ax.set_title('Mean decoding performance Ori%s' %(ilabel*90), fontsize=14)\n",
    "    ax.set_ylim([18, 42])\n",
    "    ax.set_xlabel('Time relative to stimulus onset (s)', fontsize=14);\n",
    "    ax.set_ylabel('Accuracies (%)', fontsize=14);\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(axis = 'both', which = 'major', direction='in', top=False, right=False, labelsize = 14)\n",
    "\n",
    "## save figures\n",
    "save_figure = False\n",
    "if save_figure:\n",
    "#     fig_path = project_path + '/data_v5/saved_figures/modelTrain_rs250_ica_allChans/'\n",
    "    fig_path = project_path + '/data_v5/saved_figures/modelTrain_rs250_ica_occipital/'\n",
    "    if not os.path.exists(fig_path): os.makedirs(fig_path);\n",
    "    fig.savefig(fig_path+\"modelTrain_acc_mean_find_multiOptimalTime_smoothed.pdf\", bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the optimal time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_time_idx)\n",
    "# save data\n",
    "save_data = True\n",
    "if save_data:\n",
    "    data_path = project_path + 'data_v5/saved_source_data/'\n",
    "    if not os.path.exists(data_path): os.makedirs(data_path)\n",
    "    np.save(data_path+'optimal_time_idx_occipital_acc_matrix', optimal_time_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
